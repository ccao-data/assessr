---
title: "Sales Ratio Study with Real Data"
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

AssessR can easily be used with various data to conduct a sales ratio study. In this vignette, we demonstrate how to use AssessR to produce sales ratio statistics using real data from the Cook County Assessor's Office (CCAO). The CCAO publishes residential assessments and sales anually on the [Cook County Open Data Portal](https://datacatalog.cookcountyil.gov/Property-Taxation/Cook-County-Assessor-s-Residential-Assessments/uqb9-r7vn). 

## Basics of sales ratio studies

A sales ratio is simply the ratio of the assessor's estimate of a property's value to the sale price of a property. A sales ratio study is a report on how accurately and fairly an assessor predicted property values. The CCAO has a [rigorous set of rules](https://gitlab.com/ccao-data-science---modeling/documentation/wiki_content/-/blob/master/sops/sales-ratio-studies.md) that govern how sales ratios are conducted.

In general, there are four important statistics produced in sales ratio studies, listed in the table below. It is important to understand that these statistics are calculated based on properties that sell. In most jurisdictions, the number of properties that sell in any single year is a very small percentage of the overall number of properties in the jurisdiction. In order to characterize the quality of the assessment role in a jurisdiction, we draw an inference from this small number of properties. 

| Statistic  | Acceptable Range  | Interpretation |
|---|---| --- |
|COD   | 5 - 15   | How often properties with the *same* sale price receive the same predicted market value. Lower CODs indicate more fairness between similarly priced properties. |
|PRD   | .98 - 1.03  | How often properties with *different* sale prices receive the proportionately different predicted market values. Lower PRDs indicate more fairness between low and high priced properties. |
|PRB   | -.05 - .05  | PRB is a different approach to measuring fairness across homes with different sale prices. |
|Median Assessment Ratio   |  .095 - 1.05 | The median ratio measures whether, on average, assessments accurately reflect sale prices | 
|Sales Chasing (E.4)   | $\le$ 5%  | Measures the degree to which the statistics above are *true* reflections of the quality of assessments. |

### Interpretation of sales ratio statistics

Suppose you have a jurisdiction with a median ratio of one and a COD of 20. This indicates that, on average, the assessor predicts the sale price of properties accurately, but with a high dispersion. To use the dart board analogy, the assessor's darts fall in a wide circle centered around the bullseye. On the other hand, if the median ratio is greater than one, and the COD is lower than 10, this indicates that the assessor consistently over-estimates the value of properties in their jurisdiction.

Suppose you have a jurisdiction with a low COD and high PRD & PRB. This indicates that the assessor consistently under-estimates higher value properties, and over-estimates lower value properties. Properties of similar values receive similar estimates, but there is structural inequality in the overall system.

Finally, suppose you have a jurisdiction with CODs, PRDs, and PRBs all within the acceptable range, but there is strong evidence of selective appraisals. In this case, the sales value statistics should be disregarded, since they are based on a non-random selection of the underlying set of properties. They cannot be used to characterize the quality of the assessment role.

## Loading data into R

There are many ways to load data into R. Below are some examples of loading data.

### RSocrata

[RSocrata](https://github.com/Chicago/RSocrata) is a package developed by the City of Chicago to wrap Socrata API requests. It allows you to easily pass a Socrata app token, which will remove the API limit on the number of rows returned. Example usage is shown below. Replace the login details with your own.

```{r, eval=FALSE}
library(RSocrata)

# Load unlimited rows of assessment data, default is 1,000
assessments <- read.socrata(
  "https://datacatalog.cookcountyil.gov/resource/uqb9-r7vn.json",
  app_token = "YOURAPPTOKENHERE",
  email     = "user@example.com",
  password  = "fakepassword"
)
```

### jsonlite

Socrata can also return raw JSON if you manually construct a query URL. Follow the [API docs](https://dev.socrata.com/foundry/datacatalog.cookcountyil.gov/uqb9-r7vn) to alter your query. The raw JSON output can be read using the `read_json()` function from `jsonlite`.

```{r}
library(jsonlite)

# Load 100k rows of assessment data
assessments <- read_json(
  "https://datacatalog.cookcountyil.gov/resource/uqb9-r7vn.json?$limit=100000",
  simplifyVector = TRUE
)

# Load 100k rows of sales data
sales <- read_json(
  "https://datacatalog.cookcountyil.gov/resource/5pge-nu6u.json?$limit=100000",
  simplifyVector = TRUE
)

```

### From a CSV or Excel

R can read Excel and CSV files stored on your computer. 

```{r, eval=FALSE}

library(readxl)

# CSV files
assessments <- read.csv(file = 'C:\Users\MEEE\Documents\.... where is your file ?')
sales <- read.csv(file = 'C:\Users\MEEE\Documents\.... where is your file ?')

# Excel files
assessments <- read.csv(file = 'C:\Users\MEEE\Documents\.... where is your file ?')
sales <- readxl::read_excel(file = 'C:\Users\MEEE\Documents\.... where is your file ?', sheet = 'your sheet')

```

### Connecting to a relational database

The CCAO's data science team maintains a relational database on premisis. R can connect to a wide range of database engines.

``` {r, eval=FALSE}
# Connect to the database using a configured .Renviron file.
CCAODATA <- dbConnect(
  odbc(),
  .connection_string = Sys.getenv("DB_CONFIG_CCAODATA")
  )

# Fetch data from the SQL server
  assessments <- dbGetQuery(CCAODATA, paste0("
  SELECT * FRM [MY DATA TABLES]
  "))

# Disconnect DB connection
dbDisconnect(CCAODATA)

```

## Sales ratio study 

In this section, we will use data published on the [Cook County Open Data Portal](https://datacatalog.cookcountyil.gov/Property-Taxation/Cook-County-Assessor-s-Residential-Assessments/uqb9-r7vn) to produce sales ratio studies. 

### Prepare the data

Above, we pulled assessments and sales from the Open Data Portal. In order to produce our sales ratio statistics, our data needs to be formatted in 'long form,' meaninig that each row is a property in a given year.  

```{r, results='asis'}
library(assessr)
library(dplyr)
library(tidyr)
library(knitr)

# Join the two datasets based on PIN, keeping only properties that have assessed
# values AND sales
combined <- inner_join(
  assessments %>% select(pin, year, town_name, first_pass, certified, bor_result),
  sales %>% select(pin, year = sale_year, sale_price),
  by = c("pin", "year")
)

# Remove sales that are not arms length, pivot to longer, then calculate 
# the ratio for each property and assessment stage
combined <- combined %>% 
  filter(sale_price >= 10000) %>%
  pivot_longer(
    first_pass:bor_result,
    names_to = "stage",
    values_to = "assessed"
  ) %>%
  mutate_at(vars(sale_price, assessed), as.numeric) %>%
  mutate(ratio = assessed / sale_price)

```

### Sales ratio statistics by township

Cook County has jurisdictions called townships that are important units for assessment. In the chunk below, we calculate sales ratio statistics for each township in the City of Chicago.

```{r, results='asis'}
# For each town and stage, calculate COD, PRD, and PRB, and their respective
# confidence intervals then arrange by town name and stage of assessment
combined %>%
  group_by(town_name, stage) %>%
  summarise(
    n = n(),
    cod = cod(ratio),
    cod_ci = paste(round(cod_ci(ratio, nboot = 1000), 3), collapse = ", "),
    cod_met = cod_met(cod),
    prb = prb(assessed, sale_price),
    prb_ci = paste(round(prb_ci(assessed, sale_price), 3), collapse = ", "),
    prb_met = prb_met(prb)
  ) %>%
  filter(n >= 70) %>%
  mutate(stage = factor(
    stage,
    levels = c("first_pass", "certified", "bor_result"))
  ) %>%
  arrange(town_name, stage) %>%
  rename_all(toupper) %>%
  kable(format = "markdown")

```


### Median ratios by sale price

Suppose you are concerned that an assessment role is unfair to lower value homes. One way to visually see whether ratios are  systematically biased with respect to property value is to graph median ratios by decile. In our sample data, we can see each decile of sale price using the `quantile` function:

```{r, results='asis'}
library(DT)

setNames(data.frame(quantile(combined$sale_price, probs=c(0, .1,.2,.3,.4,.5,.6,.7,.8,.9,1)))
         , 'Sale Price')%>%
  add_rownames(var = "Decile") %>%
  DT::datatable( class = 'cell-border stripe'
              , rownames = FALSE
              , options = list(dom = 't')) %>%
  formatCurrency('Sale Price') 

```

Using these decile values, we can graph sale ratio across each decile of value. Here, we use the very useful `ggplot2` package to make an attractive graph.


```{r, results='asis'}
library(ggplot2)

graph_data <- combined %>%
  mutate(`Sale price decile` = case_when(
     between(sale_price, 0, 12000) ~ '$0 - $12,000'
     , between(sale_price, 12001, 124000) ~ '$12,000 - $124K'
     , between(sale_price, 124001, 160000) ~ '$124K - $160K'
     , between(sale_price, 160001, 195000) ~ '$160K - $195K'
     , between(sale_price, 195001, 236000) ~ '$195K - $236K'
     , between(sale_price, 236001, 285000) ~ '$236K - $285K'
     , between(sale_price, 285001, 340000) ~ '$285K - $340K'
     , between(sale_price, 340001, 427000) ~ '$340K - $427K'
     , between(sale_price, 427001, 549000) ~ '$427K - $549K'
     , between(sale_price, 549001, 760000) ~ '$549K - $760K'
     , sale_price > 760000  ~ '$760K+'
  )
) %>% 
  dplyr::filter(year == 2019) %>%
  group_by(`Sale price decile`) %>%
summarise(
    n = n(),
    `Median sales ratio` = median(ratio)
  ) %>%
  dplyr::filter(n>70) 

ggplot(graph_data, aes(x=`Sale price decile`, y=`Median sales ratio`)) +
  geom_point(size=3)+
  scale_y_continuous(labels = function(x) paste0(x*100, "%")) +
  theme_minimal()+
  theme(axis.text.x = element_text(angle = 45, vjust = 0.5, hjust=1)
        , legend.position = 'bottom')+
  labs(title='Median Sale Ratios: NW Suburbs',
       subtitle = 'By decile of sale price in 2019')+
  xlab(' ') + ylab(' ')
```
