---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)
```

# assessr

A package to manage, distribute, and version control commonly-used
CCAO assessment functions.

## Installation

You can install the released version of assessR directly from GitLab by running the following R command after installing `remotes`:

```{r, eval=FALSE}
remotes::install_git("https://gitlab.com/ccao-data-science---modeling/packages/assessr")
```

Once it is installed, you can use it just like any other package. Simply
call `library(assessr)` at the beginning of your script.

## Assessment Functions

This package contains functions to calculate [sales ratio study performance statistics](https://www.iaao.org/media/standards/Standard_on_Ratio_Studies.pdf). The settings of these functions are governed by CCAO Data Science Department SOPs. Do not change them without asking.

### Example Usage

These functions can be used to calculate the COD, PRD, or PRB of a set of ratios. 

```{r, warning=FALSE, message=FALSE}
library(assessr)
library(dplyr)
library(knitr)

data("ratios_sample")

# Calculate COD
cod_func(ratios_sample$ratios, bootstrap_n = 1000)

# Calculate PRB
prb_func(
  ratios_sample$ratios,
  ratios_sample$assessed_values,
  ratios_sample$sales
)

```

They can also by applied by group. For example, to get each statistic by township.

```{r, warning=FALSE}
ratios_sample %>%
  group_by(town) %>%
  summarise(
    COD = cod_func(ratios, bootstrap_n = 1000)$COD,
    PRD = prd_func(ratios, sales, bootstrap_n = 1000)$PRD,
    PRB = prb_func(ratios, sales, assessed_values)$PRB
  )

```

You can even use `dplyr` witchcraft to calculate every stat for every group at the same time.

```{r, results='asis'}
ratios_sample %>%
  group_by(town) %>%
  group_modify(~ {
    bind_rows(
      cod_func(.x$ratios, bootstrap_n = 1000),
      prd_func(.x$ratios, .x$sales, bootstrap_n = 1000),
      prb_func(.x$ratios, .x$sales, .x$assessed_values)
    )
  }) %>%
  summarise_each(list(~ first(.x[!is.na(.x)]))) %>%
  kable(format = "markdown")

```

## Using Real Data

This package can easily be used with data from the [Cook County Open Data Portal](https://datacatalog.cookcountyil.gov/Property-Taxation/Cook-County-Assessor-s-Residential-Assessments/uqb9-r7vn) to analyze assessment performance. To measure assessment performance, you will need to gather both sales and assessed values. These are stored in two separate datasets on the data portal.

### With RSocrata

[RSocrata](https://github.com/Chicago/RSocrata) is a package developed by the City of Chicago to wrap Socrata API requests. It allows you to easily pass a Socrata app token, which will remove the API limit on the number of rows returned. Example usage is shown below, replacing the login details with your own.

```{r, eval=FALSE}
library(assessr)
library(RSocrata)

# Load unlimited rows of assessment data, default is 1,000
assessments <- read.socrata(
  "https://datacatalog.cookcountyil.gov/resource/uqb9-r7vn.json",
  app_token = "YOURAPPTOKENHERE",
  email     = "user@example.com",
  password  = "fakepassword"
)
```

### With jsonlite

Socrata can also return raw JSON if you manually construct a query URL. Follow the [API docs](https://dev.socrata.com/foundry/datacatalog.cookcountyil.gov/uqb9-r7vn) to alter your query. The raw JSON output can be read using the `read_json()` function from `jsonlite`.

```{r}
library(assessr)
library(jsonlite)

# Load 100k rows of assessment data
assessments <- read_json(
  "https://datacatalog.cookcountyil.gov/resource/uqb9-r7vn.json?$limit=100000",
  simplifyVector = TRUE
)

# Load 100k rows of sales data
sales <- read_json(
  "https://datacatalog.cookcountyil.gov/resource/5pge-nu6u.json?$limit=100000",
  simplifyVector = TRUE
)


```

### Example Analysis

Using the collected assessment and sales data, we can perform a rudimentary analysis and measure the performance of each town ship at each stage of assessment. 

```{r, results='asis'}
library(dplyr)
library(tidyr)
library(knitr)

# Join the two datasets based on PIN, keeping only properties that have assessed
# values AND sales
combined <- inner_join(
  assessments %>% select(pin, year, town_name, first_pass, certified, bor_result),
  sales %>% select(pin, year = sale_year, sale_price),
  by = c("pin", "year")
)

# Remove sales that are not arms length, pivot to longer, then calculate 
# the ratio for each property and assessment stage
combined <- combined %>% 
  filter(sale_price >= 10000) %>%
  pivot_longer(first_pass:bor_result, names_to = "stage", values_to = "av") %>%
  mutate_at(vars(sale_price, av), as.numeric) %>%
  mutate(ratio = av / sale_price)


# For each town and stage, calculate COD, PRD, and PRB, then arrange by stage
# and town name
combined %>%
  group_by(town_name, stage) %>%
  summarise(
    N = n(),
    COD = cod_func(ratio, bootstrap_n = 1000, suppress = TRUE)$COD,
    PRD = prd_func(ratio, sale_price, bootstrap_n = 1000, suppress = TRUE)$PRD,
    PRB = prb_func(ratio, sale_price, av, suppress = TRUE)$PRB
  ) %>%
  mutate(stage = factor(
    stage,
    levels = c("first_pass", "certified", "bor_result"))
  ) %>%
  arrange(town_name, stage) %>%
  drop_na() %>%
  kable(format = "markdown")

```


